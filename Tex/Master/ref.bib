@string{cviu = "Computer Vision and Image Understanding"}
@string{pami = "IEEE Transactions on Pattern Analysis and Machine Intelligence"}
@string{ijcv = "International Journal of Computer Vision"}
@string{nips = "Thirty-second Conference on Neural Information Processing Systems"}
@string{acmmm = "Proc.of ACM International Conference Multimedia"}
@string{sigir = "Proc.of ACM SIGIR Conference on Research and Development in Information Retrieval"}
@string{iccv = "Proc.of IEEE International Conference on Computer Vision"}
@string{cvpr = "Proc.of IEEE Computer Vision and Pattern Recognition"}
@string{iros = "Proc.of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"}
@string{eccv = "Proc.of European Conference on Computer Vision"}
@string{mir = "Proc.of ACM SIGMM International Workshop on Multimedia Information Retrieval"}
@string{civr = "Proc.of ACM International Conference on Image and Video Retrieval"}
@string{corr = ""}

@InProceedings{dog01, 
  author={Komori,Y. and Fujieda,T. and Ohno,K. and Suzuki,T. and Tadokoro,S.},
  title={Detection of Continuous Barking Actions from Search and Rescue Dogs' Activities Data},
  booktitle=iros,
  year={2015},
  pages={630--635}
}

@InProceedings{whoretthedog,
  author={Ehsani,K. and Bagherinezhad,H. and Redmon,J. and Mottaghi,R. and Farhadi,A.},
  title={Who Let The Dogs Out? Modeling Dog Behavior From Visual Data},
  booktitle=cvpr,
  year={2018},
}

@InProceedings{yumi2014first,
      author={Y,Iwashita. and A,Takamine. and R,Kurazume. and M. S. Ryoo.},
      title={First-Person Animal Activity Recognition from Egocentric Videos},
      booktitle={Proc.of International Conference on Pattern Recognition (ICPR)},
      year={2014},
      month={August},
      address={Stockholm, Sweden}
} 

@Inproceedings{aytar2016soundnet,
  title={Soundnet: Learning sound representations from unlabeled video},
  author={Aytar, Y and Vondrick, C and Torralba, A A},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@Conference{Kitani-2011-109824,
author = {Kris M. Kitani and Takahiro Okabe and Yoichi Sato and Akihiro Sugimoto},
title = {Fast Unsupervised Ego-Action Learning for First-person Sports Videos},
booktitle = {Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2011)},
year = {2011},
month = {June},
pages = {3241 -3248},
}

@Inproceedings{hara3dcnns,
  author={Kensho Hara and Hirokatsu Kataoka and Yutaka Satoh},
  title={Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={6546--6555},
  year={2018},
}

@misc{buycott,
author={ResqueDog Association Japan},
title={resque-dog},
years={2018},
howpublished={\url{http://buycott.me/10for1/rescue-dog.html}},
note={Accessed: 2019-01-08}
}
@misc{impact,
author={Cabinet Office, Government of Japan},
title={Impulsing Paradigm Change through Disruptive Technologies Program},
years={2014},
howpublished={\url{https://www.jst.go.jp/impact/index.html}},
note={Accessed: 2019-01-08}
}

@article{multisensory2018,
  title={Audio-Visual Scene Analysis with Self-Supervised Multisensory Features},
  author={Owens, A and Efros, A},
  booktitle=cvpr, 
  journal={arXiv preprint arXiv:1804.03641},
  year={2018},
  memo="動画から音の発生源が画像のどこにあるかを推定する"
}

@InProceedings{tran14,
  author="Tran, D. and Bourdev, L. and Fergus, R. and Torresani, L. and Paluri, M.", 
  title=" {\href{https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Tran_Learning_Spatiotemporal_Features_ICCV_2015_paper.pdf}{Learning Spatiotemporal　Features with 3D Convolutional Networks}} ", 
  booktitle=cvpr, 
  year="2014", 
  memo="大規模動画データセットを学習するために3次元のConvolutionalnetworks(3dconvnets)を利用した。4つのベンチマークで2Dconvnetsの既存手法を上回り、内2つでは最高水準（当時）となった。" 
}
@inproceedings{simonyan2014two,
  title="\href{https://papers.nips.cc/paper/5353-two-stream-convolutional-networks-for-action-recognition-in-videos.pdf}{Two-stream convolutional networks for action recognition in videos}",
  author="Simonyan, K. and Zisserman, A.",
  booktitle="Advances in Neural Information Processing Systems",
  pages="568--576",
  year="2014"
}
@article{wang2015towards,
  title={\href{https://arxiv.org/pdf/1507.02159.pdf}{Towards good practices for very deep two-stream convnets}},
  author={Wang, L. and Xiong, Y. and Wang, Z.  and Qiao, Y. },
  booktitle=cvpr,
  journal={arXiv preprint arXiv:1507.02159},
  year={2015},
}
@InProceedings{a,
  author="Feichtenhofer, C. and  Pinz, A. and Zisserman, A. ",
  title="Convolutional Two-Stream Network Fusion for Video Action Recognition",
  booktitle=cvpr,
  year="2016",
  memo="ConvolutionalNeuralNetworksを利用した動作認識。Two-Streamの改良版であり、fusionlayerを追加することでucf-101,HMDB-51において最高水準の精度となった。"
}
@article{gedas2017dblp,
  author    = {Gedas, B and Stella, X Y and Hyun, S P and Jianbo, S},
  title     = {Am {I} a Baller? Basketball Skill Assessment using First-Person Cameras},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.05365},
  booktitle = iccv,
  memo = "弱教師つきのビデオにより特定の評価者の好みに合わせたモデルを学習。バスケットボールのルールは教えていないが、評価に繋がる行動も検出可能になった"
}
@article{minghuang2016fpar,
  author    = {Minghuang, M and Haoqi, F and Kris, M. K},
  title     = {Going Deeper into First-Person Activity Recognition},
  year      = {2016},
  url       = {http://www.cs.cmu.edu/~kkitani/pdf/MFK-CVPR2016.pdf},
  booktitle = cvpr,
  memo = "一人称行動分類のアイデアまとめ．手の位置，動き，物体，カメラの動き特徴が重要だと最近の研究からわかっている．全部混ぜたツインストリームを提案．"
}


@inproceedings{Zach2007optical,
 author    = {Zach, C. and Pock, T. and Bischof, H.},
 title     = {A Duality Based Approach for Realtime TV-L1 Optical Flow},
 booktitle = {Proc.of the 29th DAGM Conference on Pattern Recognition},
 year      = {2007},
 isbn      = {978-3-540-74933-2},
 location  = {Heidelberg, Germany},
 pages     = {214--223},
 numpages  = {10},
 url       = {http://dl.acm.org/citation.cfm?id=1771530.1771554},
 acmid     = {1771554},
 publisher = {Springer-Verlag},
 address   = {Berlin, Heidelberg},
 memo      = "Opencv2で実装されているOptical flow"
} 
